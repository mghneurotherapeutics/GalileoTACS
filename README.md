# Galileo TACS

This repository holds analysis code for the manuscript "Altering Alpha-Frequency Brain Oscillations with Rapid Analog Feedback-Driven Neurostimulation" currently accepted to PLOS ONE.

The code was developed and run by Matthew Boggess under the supervision of Alik Widge (primary author).

## Layout

- code:
  - galileoTACS_analysis: Jupyter notebook containing structured analysis code run for the manuscript. Running this will reproduce the reported figures and results.
  - statistics.py: Helper functions for the bootstrap and permutation tests.
  - plotting.py: Functions used to generate the manuscript figures.
  - data_processing.py: Miscellaneous data processing utility functions.
  - experiment_config.json: Config file holding many important analyis parameters used by the scripts.
  - condition_info.csv: Table holding stimulation condition information for the various experimental runs.
- plots: Folder holding copies of the manuscript figures. Generated by the galileoTACS_analysis notebook.
- environment.yml: Anaconda environment file detailing the Python environment used to produce the manuscript results.

## Manuscript Information

Manuscript Title: Altering Alpha-Frequency Brain Oscillations with Rapid Analog Feedback-Driven Neurostimulation
Authors: Alik Sunil Widge, Matthew Boggess, Alexander P Rockhill, Andrew Mullen, Shivani Sheopory, Roman Loonis, Daniel Freeman, Earl K Miller

Current Status: Pending at PLOS ONE
  - Paper submitted to Frontiers on June 27, 2017. The initial commit represents the code in the state used to generate the figures for the initial submission.
  - It was returned with reviewer comments and then resubmitted with revision on November 3, 2017. The commit with message "revisions done: code that provided revisions submission" represents the commit that has the code at the status when revisions were submitted.
  - It was rejected from Frontiers after review. We cleaned up and then resubmitted to eLIFE.

## Computing Environment & Dependencies

### Python

Most of the analysis was done with Python. I have included an environment.yml file that one can use to recreate the Python environment with anaconda. Instructions for installing anaconda can be found <a href="https://conda.io/docs/user-guide/install/download.html">here</a>. Once installed you can run the following to create a conda environment and switch to it:

	conda env create -f environment.yml
	source activate galileo

For more information on conda environments see <a href="https://conda.io/docs/user-guide/tasks/manage-environments.html">here</a>. Within the galileo environment you can then run all of the Python code.

Additionally, I highly recommend setting up jupyter notebook extensions to allow a table of contents for navigating the juptyer analysis notebook. This can be done by following steps 2 & 3 <a href="https://github.com/ipython-contrib/jupyter_contrib_nbextensions">here</a> (step 1 has already been done and is packaged in the environment). The extension is called Table of Contents (2). As a result, you will be able to click to different sections in the analysis notebook without having to scroll through.

### MNE-C Tools

Instructions for installing and sourcing the MNE-C tools can be found <a href="https://mne-tools.github.io/stable/install_mne_c.html">here</a>. This code only uses the mne_browse_raw
function which can be evoked at the command line. Only compatible with Linux and MacOS.

mne_browse_raw was used to inspect the raw data and mark stimulation onsets and offsets. The MNE-C tools are not needed beyond this step.

### Blackrock & MATLAB

The original raw data comes in a Blackrock recording array specific format described <a href="http://support.blackrockmicro.com/KB/View/166838-file-specifications-packet-details-headers-etc">here</a>.

This code used version 4.4.0.0 of the NPMK toolkit with MATLAB R2015b to extract the raw data into .mat files. The NPMK toolkit can be downloaded <a href="https://github.com/BlackrockMicrosystems/NPMK/releases">here</a>.

MATLAB & the NPMK toolkit were only used to extract the data from the blackrock format and are not needed beyond this step.

### Computing Specs

All analysis was run on a Dell PowerEdge T330 Tower Server running CentOS7 with 64 GB of RAM.

All of the data, including raw and processed formats, requires 122 GB of storage space. This is due to inefficient repetition of the raw data being saved out in different formats as part of the extraction process.
Working with only the processed data starting from epochs or the final version of the raw data results in 30 or 45 GB of space needed respectively.

Due to the large file sizes, the code is quite memory intensive, especially if using multiple threads.


